## Approaches to Classification

### Study Goals

*Theoretical (T)*

- Learn how generative models work
- Become familiar with LDA, QDA and naive Bayes classifier
- Distinguish between generative and discriminative approaches

*Practical (P)*

- Get to know how to fit a generative model in `mlr`

### Preparation

1.  Watch the following video  (sorry, rather low volume...):
    <center>
    ![](https://www.youtube.com/watch?v=hXQq-lryqtE&list=PLMyWaJl2LoXyhFvMjtbBGs0Pi8khHbKm3&index=4&t=0s){width="75%"}
    </center>

### Exercises
  
#### *(T)* Quiz
  
```{r classif-approaches-quiz, echo=FALSE}
question("Which statements are false?",
  answer("In LDA, each class density is modeled as a multivariate Gaussian with unequal covariance.", correct = TRUE),
  answer("In QDA, each class density is modeled as a multivariate Gaussian with equal covariance", correct = TRUE),
  answer("In the Naive Bayes classifier, covariance matrices can differ over the classes but are assumed to be diagonal.")
)
```

#### *(P)* Qualitative comparison of LDA, QDA, and naive Bayes

In this demo we want to compare LDA, QDA, and naive Bayes by looking at the decision boundaries (hint: with `listLearners(properties = "multiclass")` you get a list with all available learner suited for multiclass classification). Use `plotLearnerPrediction()` to visualize the decision boundaries for the features `Sepal.Length` and `Sepal.Width`. You can use the build in iris task `iris.task` of `mlr`. Store the plot for each model and plot them underneath each other with `grid.arrange()` from the `gridExtra` package:


```{r generative-approaches, exercise=TRUE, exercise.lines=8, fig.height=8}
set.seed(123)
gg1 = plotLearnerPrediction(..., task = iris.task, features = ...)
gg2 = plotLearnerPrediction(..., task = iris.task, features = ...)
gg3 = plotLearnerPrediction(..., task = iris.task, features = ...)

gridExtra::grid.arrange(gg1, gg2, gg3, ncol = 1)
```

```{r generative-approaches-hint-1}
# The mlr learner are:
"classif.lda"
"classif.qda"
"classif.naiveBayes"
# You can directly use the string instead of a learner.
```

```{r generative-approaches-hint-2}
# You can specify the used features in 'plotLearnerPrediction()' by setting the features argument: 
plotLearnerPrediction("classif.lda", task = iris.task, features = c("Sepal.Length", "Sepal.Width"))
```


```{r generative-approaches-solution}
gg1 = plotLearnerPrediction("classif.lda", task = iris.task, 
                            features = c("Sepal.Length", "Sepal.Width"))
gg2 = plotLearnerPrediction("classif.qda", task = iris.task, 
                            features = c("Sepal.Length", "Sepal.Width"))
gg3 = plotLearnerPrediction("classif.naiveBayes", task = iris.task, 
                            features = c("Sepal.Length", "Sepal.Width"))

gridExtra::grid.arrange(gg1, gg2, gg3, ncol = 1)
```

```{r lda-qda-naiveBayes-quiz, echo=FALSE}
question("What can you observe?",
  answer("The decision boundaries of all classifiers looks equal."),
  answer("The naive Bayes classifier has linear decision boundaries due to the simple construction."),
  answer("LDA is the only classifier with linear decision boundaries.", correct = TRUE),
  answer("QDA has non-linear decision boundaries due to the different covariances in each class.", correct = TRUE)
)
```
