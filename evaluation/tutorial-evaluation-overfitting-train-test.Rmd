## Training Error, Test Error, and Overfitting

### Study Goals

*Theoretical (T)*

- Learn what overfitting means
- Get familiar with simple performance measures for regression and classification

*Practical (P)*

- See how k-NN overfits for small $k$

### Preparation

1.  *(T)* Watch the following videos:
    <center>
    ![](https://youtu.be/zSlrfST8bEg){width="75%"}
    </center>
    <!-- <a href="https://github.com/compstat-lmu/lecture_i2ml/blob/master/slides-pdf/slides-overfitting.pdf" target="_blank">Slideset</a> -->
    <center>
    ![](https://youtu.be/dpZLGIf97m0){width="75%"}
    </center>
    <!-- <a href="https://github.com/compstat-lmu/lecture_i2ml/blob/master/slides-pdf/slides-overfitting.pdf" target="_blank">Slideset</a> -->
    <center>
    ![](https://youtu.be/GOTPjCXhiS8){width="75%"}
    </center>
    <!-- <a href="https://github.com/compstat-lmu/lecture_i2ml/blob/master/slides-pdf/slides-overfitting.pdf" target="_blank">Slideset</a> -->

1. *(P)* You should have done the [tutorial about k-NN](https://compstat-lmu.shinyapps.io/01_tutorial/#section-k-nearest-neighbors)

### Exercises

#### *(T)* Quiz

```{r overfitting-quiz, echo=FALSE}
# quiz(caption = "Basic Terminology",
question("Which statements are true?",
    answer("Overfitting means that the model performs very well on the training data."),
    answer("Overfitting means that the model performs much better on the training data than on the test data.", correct = TRUE),
    answer("A good test performance is an indicator of overfitting."),
    answer("The linear model is well known to overfit very fast."),
    answer("Overfitting risk increases with model complexity", correct = TRUE),
    answer("Constraining the hypothesis space helps the learner to find a good hypothesis."),
    answer("Goodness-of-fit measures like $R^2$, likelihood, AIC, BIC and deviance are all based on the test error")
)
```

#### *(P)* Overfitting k-NN

To visually see how the number of nearest neighbors affects the overfitting behavior we simulate data as followed:

1.  Draw 100 observations of a binary target variable with equal distributed classes `1` and `2`.
    ```{r, eval=FALSE}
    class <- sample(c(1, 2), size = 100, replace = TRUE)
    ```

1. Simulate data with two normally distributed features `x` and `y` and a target variable `class`:
    * Class `1` should have a mean of $2$ and standard deviation of $1$
    * Class `2` should have a mean of $4$ and standard deviation of $2$
    * `class` should contain the classes as factor or character variable
    ```{r, eval=FALSE}
    df_sim <- data.frame(x = rnorm(100, mean = 2*class, sd = class), y = rnorm(100, mean = 2*class, sd = class), class = as.character(class))
    ```

1.  Generate a task out of the simulated data with `target = "class"` and define the k-NN learner with `k = 1`:
    ```{r, eval=FALSE}
    task_sim <- TaskClassif$new(id = "2_gaussians", backend = df_sim, target = "class")
    kknn_learner <- lrn("classif.kknn", k = 1)
    ```

1.  Finally, call `plot_learner_prediction()` on the learner and task:
    ```{r, eval=FALSE}
    plot_learner_prediction(learner = kknn_learner, task = task_sim)
    ```

Now, put all together and vary `k` to see how the overfitting behavior of k-NN reacts on the choice of `k`:

```{r kknn-overfitting, exercise=TRUE}
set.seed(123)
class <-
df_sim <-

task_sim <-
kknn_learner <-

plot_learner_prediction(learner = ..., task = ...)
```

```{r kknn-overfitting-solution}
set.seed(123)
class <- sample(c(1, 2), size = 100, replace = TRUE)
df_sim <- data.frame(x = rnorm(100, mean = 2*class, sd = class), y = rnorm(100, mean = 2*class, sd = class), class = as.character(class))

task_sim <- TaskClassif$new(id = "2_gaussians", backend = df_sim, target = "class")
kknn_learner <- lrn("classif.kknn", k = 1)

plot_learner_prediction(learner = kknn_learner, task = task_sim)
```
